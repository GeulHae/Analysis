{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeulHae/GeulHae/blob/dev_dataAnalysis/Sweep_pytorch_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLpv150CbV1y"
      },
      "source": [
        "# Sweep pytorch tutorial\n",
        "\n",
        "ğŸ“¢ í•´ë‹¹ ë…¸íŠ¸ë¶ì€ Wandb ê³µì‹ í™ˆí˜ì´ì§€ ì¤‘ ë‹¤ìŒ ë‚´ìš©ì„ ì°¸ê³ í–ˆìŠµë‹ˆë‹¤. \n",
        "  \n",
        "[Organizing Hyperparameter Sweeps in PyTorch with W&B](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Organizing_Hyperparameter_Sweeps_in_PyTorch_with_W%26B.ipynb#scrollTo=6IgMNFFT2qe_)  \n",
        "[Sweep from Jupyter Notebook](https://docs.wandb.ai/v/ko/sweeps/python-api)  \n",
        "\n",
        "\n",
        "### ëª©ì°¨  \n",
        "Step 0: W&B Setupí•˜ê¸°  \n",
        "Step 1: Congfig ì •ì˜í•˜ê¸°  \n",
        "Step 2: Dataloader í•¨ìˆ˜ ì •ì˜í•˜ê¸°  \n",
        "Step 3: ëª¨ë¸ ì •ì˜í•˜ê¸°  \n",
        "Step 4: Train í•¨ìˆ˜ì™€ Vaild í•¨ìˆ˜ ì •ì˜í•˜ê¸°  \n",
        "Step 5: Sweep ì‹¤í–‰í•˜ê¸°  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrKOiaIRbV10"
      },
      "source": [
        "## Step 0: W&B Setupí•˜ê¸°\n",
        "colabì—ì„œ WandBë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ wandb modulì„ install í•´ì•¼í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TVDfr4lSZwq"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import wandb\n",
        "import math\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bS69IoKmbV10"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install wandb --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KOburhAShIc"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHyx1L5STTaW"
      },
      "source": [
        "## Step1. Config ì •ì˜í•˜ê¸°\n",
        "\n",
        "sweepì— í•„ìš”í•œ config íŒŒì¼ì„ ì •ì˜í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCtuPcO7ShFm"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    'name' : 'bayes-test',\n",
        "    'method': 'random',\n",
        "    'metric' : {\n",
        "        'name': 'val_loss',\n",
        "        'goal': 'minimize'   \n",
        "        },\n",
        "    'parameters' : {\n",
        "        'optimizer': {\n",
        "            'values': ['adam', 'sgd']\n",
        "            },\n",
        "        'dropout': {\n",
        "            'values': [0.3, 0.4]\n",
        "            },\n",
        "        'learning_rate': {\n",
        "            'distribution': 'uniform',\n",
        "            'min': 0,\n",
        "            'max': 0.1\n",
        "            },\n",
        "        'epochs': {\n",
        "            'values': [5, 6]\n",
        "            },\n",
        "        'batch_size': {\n",
        "            'distribution': 'q_log_uniform',\n",
        "            'q': 1,\n",
        "            'min': math.log(32),\n",
        "            'max': math.log(256),\n",
        "            }\n",
        "        }\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBBWJbcYaDzb"
      },
      "source": [
        "## Step2. Dataloader í•¨ìˆ˜ ì •ì˜í•˜ê¸°\n",
        "mnist í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ì„œ dataloaderë¥¼ êµ¬ì„±í•˜ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3NwvXGdShDO"
      },
      "outputs": [],
      "source": [
        "def SweepDataset(batch_size):\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "         transforms.Normalize((0.1307,), (0.3081,))])\n",
        "    \n",
        "    train_data = datasets.MNIST(\".\", \n",
        "                train=True, \n",
        "                download=True,\n",
        "                transform=transform)\n",
        "    \n",
        "    test_data = datasets.MNIST(\".\", \n",
        "                train=False, \n",
        "                download=True,\n",
        "                transform=transform)\n",
        "    \n",
        "    \n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size)\n",
        "    test_loader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "    return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc2GfRccaH7c"
      },
      "source": [
        "## Step3. ëª¨ë¸ ì •ì˜í•˜ê¸°\n",
        "ëª¨ë¸ê³¼ optimizerë¥¼ ì •ì˜í•´ì¤ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "om_xkH-_ShAk"
      },
      "outputs": [],
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, dropout):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, 1, 1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 3, 1, 1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Linear(64 * 7 * 7, 128, bias=True), nn.ReLU(),\n",
        "            nn.Dropout2d(p=dropout))\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Linear(128, 84), nn.ReLU(),\n",
        "            nn.Dropout2d(p=dropout))\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = x.view(x.size(0),-1) \n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzCoH_hpT7qI"
      },
      "outputs": [],
      "source": [
        "def build_optimizer(network, optimizer, learning_rate):\n",
        "    if optimizer == \"sgd\":\n",
        "        optimizer = optim.SGD(network.parameters(),\n",
        "                              lr=learning_rate, momentum=0.9)\n",
        "    elif optimizer == \"adam\":\n",
        "        optimizer = optim.Adam(network.parameters(),\n",
        "                               lr=learning_rate)\n",
        "    return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYZAPlIKaMZ2"
      },
      "source": [
        "## Step4. Train í•¨ìˆ˜ì™€ Vaildí•¨ìˆ˜ ì •ì˜í•˜ê¸°\n",
        "trainí•¨ìˆ˜ëŠ” í•™ìŠµì„ ì§„í–‰í•˜ë©´ì„œ lossë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.  \n",
        "vaildí•¨ìˆ˜ëŠ” í•™ìŠµ ì¤‘ê°„ì— Accuracyë¥¼ ì‚¬ìš©í•´ì„œ í‰ê°€í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFX6aIXpSg9s"
      },
      "outputs": [],
      "source": [
        "def train(model, loader, criterion, optimizer, device, config, wandb):\n",
        "    model.train()\n",
        "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
        "\n",
        "    for epoch in range(config.epochs):\n",
        "        cumu_loss = 0\n",
        "        for images, labels in loader:\n",
        "            images, labels  = images.to(device), labels.to(device)\n",
        "\n",
        "            output = model(images)\n",
        "            loss = criterion(output, labels)\n",
        "            cumu_loss += loss.item()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        avg_loss = cumu_loss / len(loader)\n",
        "        wandb.log({\"train_loss\": avg_loss}, step=epoch)  \n",
        "        print(f\"TRAIN: EPOCH {epoch + 1:04d} / {config.epochs:04d} | Epoch LOSS {avg_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLehH0A5pKER"
      },
      "outputs": [],
      "source": [
        "def vaild(model, loader, criterion, device,  wandb):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        correct, test_loss = 0, 0\n",
        "        for data, target in loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            \n",
        "            test_loss += criterion(output, target).item()\n",
        "            \n",
        "            pred = output.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            \n",
        "    \n",
        "    val_loss = test_loss / len(loader)\n",
        "    print(f\"VALID: LOSS {val_loss:.4f} | Accuracy {val_loss:.4f} \")\n",
        "    wandb.log({\n",
        "        \"val_acc\": 100. * correct / len(loader.dataset),\n",
        "        \"val_loss\": val_loss})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmJSYYDzYpu3"
      },
      "source": [
        "## Step5. Sweep ì‹¤í–‰í•˜ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMADlVI6Sg7H"
      },
      "outputs": [],
      "source": [
        "def run_sweeep(config=None):\n",
        "    wandb.init(config=config)\n",
        "    \n",
        "    w_config = wandb.config\n",
        "    \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    train_loader, vaild_loader = SweepDataset(w_config.batch_size)\n",
        "    model = ConvNet(w_config.dropout).to(DEVICE)\n",
        "    optimizer = build_optimizer(model, w_config.optimizer, w_config.learning_rate)\n",
        "    \n",
        "    train(model, train_loader, criterion, optimizer, DEVICE, w_config, wandb)\n",
        "    vaild(model, vaild_loader, criterion, DEVICE, wandb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gi7BCOC3Sgro"
      },
      "outputs": [],
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=\"sweep_tutorial\", entity='pebpung')\n",
        "wandb.agent(sweep_id, run_sweeep, count=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYScswkxbV12"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "8e5e08de07fba0fb72df28d1d02d73caaafb877a45fd93aa5b25ed7e0e8c6fec"
    },
    "kernelspec": {
      "display_name": "Python 3.8.0 64-bit ('torch': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}