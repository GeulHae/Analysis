{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvWakwX6alDNw3TU2CQE8Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeulHae/GeulHae/blob/dev_dataAnalysis/classification_SeparationGo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 분리GO\n",
        "\n",
        "### 이미지처리를 활용한 분리배출 안내 서비스\n",
        "\n",
        "- 일회용품 사용량이 일회용품 사용량이 증가하면서 제대로된 분리배출이 이루어지지 않아 재활용 효율성이 떨어지는 문제가 발생\n",
        "- 분리배출 방법에 대해 사람들이 어려움을 느끼고, 올바르게 분리배출을 하지 못해 문제가 발생하는 경우 발생\n",
        "\n",
        "이러한 문제를 해결하기 위해 자동 분류 시스템을 도입하여 효율적인 분리수거를 도와주는 서비스가 필요합니다. \n",
        "이를 통해 분리배출을 할 때 어려움을 겪는 사람들도 쉽고 간편하게 분리배출을 할 수 있게 됩니다. \n",
        "\n",
        "이는 쓰레기 문제를 해결하고, 환경 및 인간의 건강과 생활환경을 개선하는데 큰 도움이 될 것입니다.\n",
        "\n",
        "\n",
        "이 프로젝트는 작은 실천으로 효율적인 재활용이 될 수 있도록 분리배출 방법을 알려주는 서비스입니다. \n",
        "분리배출을 할 때 어려움을 겪는 사람들을 위한 서비스로, 이미지 기반의 쓰레기 종류 예측을 통해, 쓰레기 분리배출의 정확성을 높이고, 효율적인 쓰레기 처리와 관리를 돕습니다.\n",
        "\n",
        "이 서비스는 홀로서기 1인가구에서 처음 겪는 주도적인 재활용품 분류에 있어 정보 및 어려움 해결을 제공하며, 새로운 지역으로 이동한 가구들에게는 지역마다 분리배출 일정이 상이하기 때문에 재활용 방법 권역별 정보 제공이 가능합니다. \n",
        "또한 분류배출 일상화 인구들에게는 재활용 방법 및 법안이 계속해서 변화하며, 같은 소재라도 사용 방법에 따라 다르게 분류되는 부분이 매우 다양하기 때문에 정보 습득 및 활용 용이성을 제공합니다.\n",
        "\n",
        "이 서비스를 활용함으로써, 분리배출을 정확히 인지하고 생활화 하는데 적립금 서비스로 연결하여 흥미 유발 및 습관, 환경에 대한 의식을 고취시키고, 적립금을 마케팅상품 구매 및 기부로 연결시켜 가정 및 사회 경제에 기여 할 수 있습니다.\n",
        "쓰레기 처리 및 관리에 대한 효율성을 높이고, 환경 문제 및 인간의 건강과 생활 환경에 큰 영향을 미치는 쓰레기 문제를 해결할 수 있습니다."
      ],
      "metadata": {
        "id": "9E4GPWGhK1LB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data set\n",
        "\n",
        "- 총 이미지 : ________개\n",
        "- 라벨 : _________개\n",
        "\n",
        "1. plastic 플라스틱(____개)\n",
        "2. \n",
        "3.\n",
        "4.\n",
        "5.\n",
        "6.\n",
        "7.\n",
        "8.\n",
        "\n"
      ],
      "metadata": {
        "id": "-ADKVtPoL3O3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plan\n",
        "\n",
        "- 데이터 불러오기\n",
        "- 이미지 전처리\n",
        "- 베이스라인 모델 설정\n",
        "- 모델 튜닝 후 성능 높이기   \n",
        "    - 데이터 증강  \n",
        "    - 전이학습\n",
        "- 모델 성능 확인\n"
      ],
      "metadata": {
        "id": "7eBhVxWWMdqj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esX--g9RKk_8"
      },
      "outputs": [],
      "source": [
        "# 필요 라이브러리 import\n",
        "\n",
        "import os\n",
        "import os.path\n",
        "import cv2\n",
        "import shutil \n",
        "import zipfile\n",
        "import datetime\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import \n",
        "import \n",
        "import \n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from tensorflow.keras.layers import Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNet, Xception, ResNet50, InceptionV3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data 불러오기 ( Drive mount )\n",
        "\n",
        "### colab에서 코드로 zip 파일 압축 풀기\n",
        "1. google 드라이브에 이미지 압축파일(zip) upload\n",
        "2. colab 에서 드라이브 마운트\n",
        "3. 압축 풀어주는 코드 작성"
      ],
      "metadata": {
        "id": "cYoyw4EANT9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 드라이브 마운트\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "zImUlgnCNaVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # %cd 압축을 풀 경로\n",
        "# # !unzip -qq \"압축파일 Path\"\n",
        "\n",
        "# %cd /content/drive/MyDrive/Colab Notebooks/challenge/data\n",
        "\n",
        "# !unzip -qq \"/content/drive/MyDrive/Colab Notebooks/challenge/data/Positive.zip\""
      ],
      "metadata": {
        "id": "yBato_E2VNnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # upload 잘 되었는지 파일 수 확인\n",
        "\n",
        "# filepaths = list(glob('content/image/*.jpg'))\n",
        "\n",
        "# len(filepaths)"
      ],
      "metadata": {
        "id": "Hech14QvVrnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 폴더 안에 파일 목록 .listdir / len 파일 수 확인\n",
        "\n",
        "# print(len(os.listdir('/content/trashs_filtered/train/plastics')))\n",
        "# print(len(os.listdir('/content/trashs_filtered/train/papers')))\n",
        "\n",
        "# print(len(os.listdir('/content/trashs_filtered/validation/plastics')))\n",
        "# print(len(os.listdir('/content/trashs_filtered/validation/papers')))"
      ],
      "metadata": {
        "id": "L0CmzeZrjDuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #현재 디렉토리 확인\n",
        "# print(os.getcwd())\n",
        "\n",
        "# # 새로운 폴더에 파일 옮기기 / 이 경로를 합쳐줘~\n",
        "# root_dir = os.path.join(os.getcwd(), 'board_papers')\n",
        "# print(root_dir)\n",
        "# #현재 디렉토리에 board_papers 폴더 생성\n",
        "# os.mkdir(root_dir)\n",
        "\n",
        "# #현재 디렉토리 변경\n",
        "# os.chdir(root_dir)\n",
        "# print(os.getcwd())"
      ],
      "metadata": {
        "id": "_xMS26G6jxLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train용 폴더 생성\n",
        "train_set_dir = os.path.join(root_dir, 'train_set')\n",
        "print(train_set_dir)\n",
        "os.mkdir(train_set_dir)\n",
        "\n",
        "train_plastic_dir = os.path.join(train_set_dir, 'plastic')\n",
        "print(train_plastic_dir)\n",
        "os.mkdir(train_plastic_dir)\n",
        "\n",
        "train_paper_dir = os.path.join(train_set_dir, 'paper')\n",
        "print(train_paper_dir)\n",
        "os.mkdir(train_paper_dir)\n",
        "     "
      ],
      "metadata": {
        "id": "hkpE2M4SkLTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#valid용 폴더 생성\n",
        "valid_set_dir = os.path.join(root_dir, 'valid_set')\n",
        "print(valid_set_dir)\n",
        "os.mkdir(valid_set_dir)\n",
        "\n",
        "valid_plastic_dir = os.path.join(valid_set_dir, 'plastic')\n",
        "print(valid_plastic_dir)\n",
        "os.mkdir(valid_plastic_dir)\n",
        "\n",
        "valid_paper_dir = os.path.join(valid_set_dir, 'paper')\n",
        "print(valid_paper_dir)\n",
        "os.mkdir(valid_paper_dir)"
      ],
      "metadata": {
        "id": "jRRjaawakcD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test용 폴더 생성\n",
        "test_set_dir = os.path.join(root_dir, 'test_set')\n",
        "print(test_set_dir)\n",
        "os.mkdir(test_set_dir)\n",
        "\n",
        "\n",
        "test_plastic_dir = os.path.join(test_set_dir, 'plastic')\n",
        "print(test_plastic_dir)\n",
        "os.mkdir(test_plastic_dir)\n",
        "\n",
        "test_paper_dir = os.path.join(test_set_dir, 'paper')\n",
        "print(test_paper_dir)\n",
        "os.mkdir(test_paper_dir)"
      ],
      "metadata": {
        "id": "iRItLr76kw28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image file name list 생성 \n",
        "# Ex) 0~2499.jpg 까지 만들때\n",
        "\n",
        "plastic_files = [f'plastic.{i}.jpg' for i in range(2500)]\n",
        "paper_files = [f'paper.{i}.jpg' for i in range(2500)]"
      ],
      "metadata": {
        "id": "pIbZrEtslH3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 폴더로 image 이동\n",
        "for file in plastic_files[:1000]:\n",
        "    src = os.path.join('/content/trashs_filtered/train/plastics', file)\n",
        "    dst = os.path.join(train_plastic_dir, file)\n",
        "    shutil.move(src, dst)\n",
        "\n",
        "for file in paper_files[:1000]:\n",
        "    src = os.path.join('/content/trashs_filtered/train/papers', file)\n",
        "    dst = os.path.join(train_paper_dir, file)\n",
        "    shutil.move(src, dst)"
      ],
      "metadata": {
        "id": "e_wyFO-clWL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir(train_plastic_dir)))\n",
        "print(len(os.listdir(train_paper_dir)))"
      ],
      "metadata": {
        "id": "CtnZ8CColtPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file in plastic_files[2000:2300]:\n",
        "    src = os.path.join('/content/trashs_filtered/validation/plastics', file)\n",
        "    dst = os.path.join(valid_plastic_dir, file)\n",
        "    shutil.move(src, dst)\n",
        "\n",
        "for file in paper_files[2000:2300]:\n",
        "    src = os.path.join('/content/trashs_filtered/validation/papers', file)\n",
        "    dst = os.path.join(valid_paper_dir, file)\n",
        "    shutil.move(src, dst)"
      ],
      "metadata": {
        "id": "sOx832IJl2iC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file in plastic_files[2300:2500]:\n",
        "    src = os.path.join('/content/trashs_filtered/validation/plastics', file)\n",
        "    dst = os.path.join(test_plastic_dir, file)\n",
        "    shutil.move(src, dst)\n",
        "\n",
        "for file in paper_files[2300:2500]:\n",
        "    src = os.path.join('/content/trashs_filtered/validation/papers', file)\n",
        "    dst = os.path.join(test_paper_dir, file)\n",
        "    shutil.move(src, dst)"
      ],
      "metadata": {
        "id": "jPMj8v64mKoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir(test_plastic_dir)))\n",
        "print(len(os.listdir(test_paper_dir)))"
      ],
      "metadata": {
        "id": "-rjqCPPRmYtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'the number of train set : {len(os.listdir(train_plastic_dir)) + len(os.listdir(train_paper_dir))}')\n",
        "print(f'the number of validn set : {len(os.listdir(valid_plastic_dir)) + len(os.listdir(valid_paper_dir))}')\n",
        "print(f'the number of test set : {len(os.listdir(test_plastic_dir)) + len(os.listdir(test_paper_dir))}')"
      ],
      "metadata": {
        "id": "5sZjPBjRmjgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 이미지 데이터 정보 파악"
      ],
      "metadata": {
        "id": "JsqB049FejBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ex) ./data에 어떤 파일들 존재 하는지 확인\n",
        "\n",
        "file_list = os.listdir('./data')\n",
        "file_list\n",
        "\n",
        "# Ex) ['Test', 'Test.jpg', 'Train', 'Train.csv']"
      ],
      "metadata": {
        "id": "MTdWIpXZenJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 이미지 경로 데이터 프레임 형태로"
      ],
      "metadata": {
        "id": "iEeGsHPdNh24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir_ = Path('/ ')\n",
        "filepaths = list(dir_.glob(r'**/*.jpg'))\n",
        "def proc_img(filepath):\n",
        "    \"\"\"\n",
        "   \t\t이미지데이터의 경로와 label데이터로 데이터프레임 만들기 \n",
        "    \"\"\"\n",
        "\n",
        "    labels = [str(filepath[i]).split(\"/\")[-2] \\\n",
        "              for i in range(len(filepath))]\n",
        "\n",
        "    filepath = pd.Series(filepath, name='Filepath').astype(str)\n",
        "    labels = pd.Series(labels, name='Label')\n",
        "\n",
        "    # 경로와 라벨 concatenate\n",
        "    df = pd.concat([filepath, labels], axis=1)\n",
        "\n",
        "    # index 재설정\n",
        "    df = df.sample(frac=1,random_state=0).reset_index(drop = True)\n",
        "    \n",
        "    return df\n",
        "\n",
        "df = proc_img(filepaths)\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "CrZLERpTNuru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of pictures: {df.shape[0]}\\n')\n",
        "print(f'Number of different labels: {len(df.Label.unique())}\\n')\n",
        "print(f'Labels: {df.Label.unique()}')"
      ],
      "metadata": {
        "id": "W0c_9HoROB9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 이미지 데이터 확인"
      ],
      "metadata": {
        "id": "utk_iphsOHr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(nrows=4, ncols=10, figsize=(15, 7),\n",
        "                        subplot_kw={'xticks': [], 'yticks': []})\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(plt.imread(df.Filepath[i]))\n",
        "    ax.set_title(df.Label[i], fontsize = 12)\n",
        "plt.tight_layout(pad=0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xIVelNZCOGCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Label Category 분포 확인"
      ],
      "metadata": {
        "id": "gIbmC9dAOXTh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "vc = df['Label'].value_counts()\n",
        "plt.figure(figsize=(9,5))\n",
        "sns.barplot(x = vc.index, y = vc, palette = \"rocket\")\n",
        "plt.title(\"Number of pictures of each category\", fontsize = 15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1HvRKNpVKzwJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 이미지 데이터 Train, Test 데이터로 분류\n",
        "\n"
      ],
      "metadata": {
        "id": "hIjjF_qwOjM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training/test split\n",
        "# train_df,test_df = train_test_split(df.sample(frac=0.2), test_size=0.1,random_state=0) #모델링 시간이 오래걸리면 사용\n",
        "\n",
        "train_df,test_df = train_test_split(df, test_size=0.1,random_state=0)\n",
        "train_df.shape,test_df.shape"
      ],
      "metadata": {
        "id": "SUY-BEmrOr9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 베이스 라인 모델\n",
        "\n",
        "- YOLOv5s ( 객체 인식분야 유명 모델, v5s 학습이 빠르며 pytorch 사용 )\n",
        "- FastRCNN\n",
        "- Transformer"
      ],
      "metadata": {
        "id": "iBXrdpFmOwQ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 전처리"
      ],
      "metadata": {
        "id": "0J7i74toOyQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   validation_split=0.2)\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory('/content/drive/MyDrive/Colab Notebooks/Data_analysis_Project/03_딥러닝_이미지분류/imagedata/data/natural_images',\n",
        "                                                 target_size = (150, 150),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical',subset='training')\n",
        "val_gen  = train_datagen.flow_from_directory('/content/drive/MyDrive/Colab Notebooks/Data_analysis_Project/03_딥러닝_이미지분류/imagedata/data/natural_images',\n",
        "                                                 target_size = (150, 150),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical',subset='validation')"
      ],
      "metadata": {
        "id": "oyWFSIHbO2ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DeepLearning CNN 모델로 베이스라인 모델링"
      ],
      "metadata": {
        "id": "zhArBXG5O5vC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialising the CNN\n",
        "cnn = tf.keras.models.Sequential()\n",
        "\n",
        "# Step 1 - Convolution\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[150, 150, 3]))\n",
        "\n",
        "# Step 2 - Pooling\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "\n",
        "# Adding convolutional layer\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "\n",
        "# Step 3 - Flattening\n",
        "cnn.add(tf.keras.layers.Flatten())\n",
        "\n",
        "# Step 4 - Full Connection\n",
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "\n",
        "# Step 5 - Output Layer\n",
        "cnn.add(tf.keras.layers.Dense(units=8, activation='softmax'))\n",
        "\n",
        "# Compiling the CNN\n",
        "cnn.compile(optimizer = 'adam', \n",
        "            loss = 'categorical_crossentropy', \n",
        "            metrics = ['accuracy'])\n",
        "cnn.summary()"
      ],
      "metadata": {
        "id": "MRImGXn1PBdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 성능 확인 (accuracy)"
      ],
      "metadata": {
        "id": "wBwAQLaVPHiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x = train_gen, validation_data = val_gen, epochs = 10)"
      ],
      "metadata": {
        "id": "sgm-vzAjPMda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 베이스 라인 모델 성능 결과 확인\n",
        "- accuracy :\n",
        "- val_accuracy :\n",
        "\n"
      ],
      "metadata": {
        "id": "OFDtN7M3PQ7R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 성능 높이기"
      ],
      "metadata": {
        "id": "xlO9gjtIPf5j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 증강(Data Augmentation)으로 이미지 로드\n",
        "\n",
        "- rotation_range - 사진 회전각도 범위; 0~180사이값\n",
        "- width_shift_range, height_shift_range - 수평과 수직으로 평행 이동시킬 범위; 전체 너비와 높이에 대한 비율값\n",
        "- shear_range - shearing transformation(전단 변환)을 적용할 각도 범위; 사진을 3D로 기울임\n",
        "- zoom_range - 사진을 확대할 범위\n",
        "- horizontal_flip - 랜덤하게 이미지를 수평으로 뒤집음\n",
        "- fill_mode - 회전이나 이동을 통해 빈 곳이 생기면 픽셀을 채우는 방법(nearest는 인접한 픽셀을 사용함)"
      ],
      "metadata": {
        "id": "CVm8LeCZPhiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_gen():\n",
        "    # 생성기 및 데이터 증강으로 이미지 로드\n",
        "    train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
        "        validation_split=0.1\n",
        "    )\n",
        "\n",
        "    test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "    )\n",
        "\n",
        "    train_images = train_generator.flow_from_dataframe(\n",
        "        dataframe=train_df,\n",
        "        x_col='Filepath', # 파일위치 열이름\n",
        "        y_col='Label', # 클래스 열이름\n",
        "        target_size=(224, 224), # 이미지 사이즈\n",
        "        color_mode='rgb', # 이미지 채널수\n",
        "        class_mode='categorical', # Y값(Label값)\n",
        "        batch_size=32,\n",
        "        shuffle=True, # 데이터를 섞을지 여부\n",
        "        seed=0,\n",
        "        subset='training', # train 인지 val인지 설정\n",
        "        rotation_range=30, # 회전제한 각도 30도\n",
        "        zoom_range=0.15, # 확대 축소 15%\n",
        "        width_shift_range=0.2, # 좌우이동 20%\n",
        "        height_shift_range=0.2, # 상하이동 20%\n",
        "        shear_range=0.15, # 반시계방햐의 각도\n",
        "        horizontal_flip=True, # 좌우 반전 True\n",
        "        fill_mode=\"nearest\"\n",
        "        # 이미지 변경시 보완 방법 (constant, nearest, reflect, wrap) 4개 존재\n",
        "    )\n",
        "\n",
        "    val_images = train_generator.flow_from_dataframe(\n",
        "        dataframe=train_df,\n",
        "        x_col='Filepath',\n",
        "        y_col='Label',\n",
        "        target_size=(224, 224),\n",
        "        color_mode='rgb',\n",
        "        class_mode='categorical',\n",
        "        batch_size=32,\n",
        "        shuffle=True,\n",
        "        seed=0,\n",
        "        subset='validation',\n",
        "        rotation_range=30,\n",
        "        zoom_range=0.15,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.15,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode=\"nearest\"\n",
        "    )\n",
        "\n",
        "    test_images = test_generator.flow_from_dataframe(\n",
        "        dataframe=test_df,\n",
        "        x_col='Filepath',\n",
        "        y_col='Label',\n",
        "        target_size=(224, 224),\n",
        "        color_mode='rgb',\n",
        "        class_mode='categorical',\n",
        "        batch_size=32,\n",
        "        shuffle=False\n",
        "    )\n",
        "    \n",
        "    return train_generator,test_generator,train_images,val_images,test_images"
      ],
      "metadata": {
        "id": "tqiAd_VUPrQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "회전각도, 확대축소, 좌우이동, 상하이동, 좌우반전 등 데이터 증강의 많은 기법을 사용  \n",
        "\n",
        "Train과 Val 데이터에 적용, Test 데이터는 학습에 사용되지 않기 때문에 증강기법 미적용"
      ],
      "metadata": {
        "id": "if9eC5O7Psh_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 전이학습 사용, 모델 성능 높이기"
      ],
      "metadata": {
        "id": "7uSVXbTLP5xn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"DenseNet121\": {\"model\":tf.keras.applications.DenseNet121, \"perf\":0},\n",
        "    \"MobileNetV2\": {\"model\":tf.keras.applications.MobileNetV2, \"perf\":0},\n",
        "    \"DenseNet201\": {\"model\":tf.keras.applications.DenseNet201, \"perf\":0},\n",
        "    \"EfficientNetB0\": {\"model\":tf.keras.applications.EfficientNetB0, \"perf\":0},\n",
        "    \"EfficientNetB1\": {\"model\":tf.keras.applications.EfficientNetB1, \"perf\":0},\n",
        "    \"InceptionV3\": {\"model\":tf.keras.applications.InceptionV3, \"perf\":0},\n",
        "    \"MobileNetV2\": {\"model\":tf.keras.applications.MobileNetV2, \"perf\":0},\n",
        "    \"MobileNetV3Large\": {\"model\":tf.keras.applications.MobileNetV3Large, \"perf\":0},\n",
        "    \"ResNet152V2\": {\"model\":tf.keras.applications.ResNet152V2, \"perf\":0},\n",
        "    \"ResNet50\": {\"model\":tf.keras.applications.ResNet50, \"perf\":0},\n",
        "    \"ResNet50V2\": {\"model\":tf.keras.applications.ResNet50V2, \"perf\":0},\n",
        "    \"VGG19\": {\"model\":tf.keras.applications.VGG19, \"perf\":0},\n",
        "    \"VGG16\": {\"model\":tf.keras.applications.VGG16, \"perf\":0},\n",
        "    \"Xception\": {\"model\":tf.keras.applications.Xception, \"perf\":0}\n",
        "}\n",
        "# Create the generators\n",
        "train_generator,test_generator,train_images,val_images,test_images=create_gen()\n",
        "print('\\n')\n",
        "\n",
        "def get_model(model):\n",
        "# Load the pretained model\n",
        "    kwargs =    {'input_shape':(224, 224, 3),\n",
        "                'include_top':False,\n",
        "                'weights':'imagenet',\n",
        "                'pooling':'avg'}\n",
        "    \n",
        "    pretrained_model = model(**kwargs)\n",
        "    pretrained_model.trainable = False # 레이어를 동결 시켜서 훈련중 손실을 최소화 한다.\n",
        "    \n",
        "    inputs = pretrained_model.input\n",
        "\n",
        "    x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\n",
        "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(8, activation='softmax')(x)\n",
        "    # Dense 분류 수에 맞게, 보통은 라벨 수 finetuning Dense\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Train모델 학습\n",
        "for name, model in models.items():\n",
        "    \n",
        "    # 전이 학습 모델 가져오기\n",
        "    m = get_model(model['model'])\n",
        "    models[name]['model'] = m\n",
        "    \n",
        "    start = perf_counter()\n",
        "    \n",
        "    # 모델 학습\n",
        "    history = m.fit(train_images,validation_data=val_images,epochs=1,verbose=0)\n",
        "    # 학습 중간에 개입시 callback 함수 이용 callbacks=[tensorboard_callback] / earlystopping\n",
        "    \n",
        "    # 학습시간과 val_accuracy 저장\n",
        "    duration = perf_counter() - start\n",
        "    duration = round(duration,2)\n",
        "    models[name]['perf'] = duration\n",
        "    print(f\"{name:20} trained in {duration} sec\")\n",
        "    \n",
        "    val_acc = history.history['val_accuracy']\n",
        "    models[name]['val_acc'] = [round(v,4) for v in val_acc]"
      ],
      "metadata": {
        "id": "bk9hA6qqQBLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시간정보를 활용하여 폴더 생성\n",
        "import datetime\n",
        "\n",
        "# 학습데이터의 log를 저장할 폴더 생성 (지정)\n",
        "log_dir = os.getcwd() + '/' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "print(log_dir)\n",
        "\n",
        "# 텐서보드 콜백 정의\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "\n",
        "# /content/20230412-011005"
      ],
      "metadata": {
        "id": "ZJfD9HfWn2dT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {log_dir}"
      ],
      "metadata": {
        "id": "aup_vjpYoKGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "             loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "earlystopping = EarlyStopping(monitor='val_loss', patience=5)                     \n",
        "\n",
        "\n",
        "hist = model.fit_generator(train_generator,\n",
        "                   epochs=50,\n",
        "                   validation_data=valid_generator,\n",
        "                   callbacks=[earlystopping, tensorboard_callback])\n",
        "     "
      ],
      "metadata": {
        "id": "4hPmwaC_oXks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "어떤 전이학습이 좋은 효율을 나타내는지 알 수 없기 떄문에 전이학습 모델들을 전부가지고 와서 비교해보는 코드를 작성, 만들어 놓은 모델 함수에 for문을 통해 전이학습모델 전부 학습"
      ],
      "metadata": {
        "id": "H7SIvpasQK8G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Data로 성능 확인"
      ],
      "metadata": {
        "id": "9GTKYkiYQa5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test데이터로 모델 성능 예측\n",
        "for name, model in models.items():\n",
        "    \n",
        "    # Predict the label of the test_images\n",
        "    pred = models[name]['model'].predict(test_images)\n",
        "    pred = np.argmax(pred,axis=1)\n",
        "\n",
        "    # Map the label\n",
        "    labels = (train_images.class_indices)\n",
        "    labels = dict((v,k) for k,v in labels.items())\n",
        "    pred = [labels[k] for k in pred]\n",
        "\n",
        "    y_test = list(test_df.Label)\n",
        "    acc = accuracy_score(y_test,pred)\n",
        "    models[name]['acc'] = round(acc,4)\n",
        "    print(f'**{name} has a {acc * 100:.2f}% accuracy on the test set**')\n",
        "   \n",
        "# Create a DataFrame with the results\n",
        "models_result = []\n",
        "\n",
        "for name, v in models.items():\n",
        "    models_result.append([ name, models[name]['val_acc'][-1], \n",
        "                          models[name]['acc'],\n",
        "                          models[name]['perf']])\n",
        "    \n",
        "df_results = pd.DataFrame(models_result, \n",
        "                          columns = ['model','val_accuracy','accuracy','Training time (sec)'])\n",
        "df_results.sort_values(by='accuracy', ascending=False, inplace=True)\n",
        "df_results.reset_index(inplace=True,drop=True)\n",
        "df_results"
      ],
      "metadata": {
        "id": "xTkljV3jQehO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습한 모델에 test셋을 통해서 전이모델별 성능을 확인 후 정확도 1에 수렴 되는 정도 확인  \n",
        "모델별 정확도 대비 Training time 비교"
      ],
      "metadata": {
        "id": "kqKgL69IQkfb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 평가/ 분석\n",
        "map곡선, loss 수준 보고 가능 하다면 best weight으로 epoch조절 / batch size 재 고려\n",
        "recall값 확인 후 탐지 불가 클래 스 및 이미지 데이터 살펴보고 원인 분석\n",
        "\n",
        "## 1. image augmentation / 다양한 모델의 앙상블 진행 해보기 ( yolo, fast-rcnn 등의 모델 다양하게 사용 )\n",
        "## 2. 문제점 빠르게 파악 train/ val set, Test set 등 여러가지 문제의 여지 살펴보기\n",
        "\n",
        "\n",
        "\n",
        "### Test set 문제 개선\n",
        "- Confidence level : 높일경우, 낮을경우 탐지 결과 비교  \n",
        "적당한 값을 찾은 뒤, 수작업으로 라벨값을 수정\n",
        "다른 클래스들에 영향을 주지 않는 선에서 조금은 과하게 탐지하도록 conf 값 설정, 이후 실제 이미지와 비교하면서 라벨이 없어야 하는 곳에 있는 경우만 삭제  \n",
        "confidence level을 보수적으로 설정하면 recall 값만 약간 낮아지지만, 관대하게 설정하면 precision값이 과하게 떨어질 수 있기 때문에 안전 감수를 위해서 confidence level만 낮추고 끝내는 것이 좋을 수도 있다.   \n",
        "confidence level을 조절하면서 육안으로 보았을 때, 이 정도는 직접 수작업으로도 가능하다 싶은 값 찾아보기\n",
        "\n",
        "- 추론 못하는 이미지 : 해당 클래스만 구별하는 모델 추가\n",
        "rotation값을 조정한 image augmentation을 살짝 추가해서 해당 클래스만 학습한 모델 별도 생성  \n",
        "rotation은 yolo 모델 내의 parameter 통해 진행 해보기  \n",
        "\n",
        "추론하지 못한 이미지 공통점 찾아서 계속해서 해결 해보기 ( 같은 류의 이미지 or 같은 류의 각도 및 변환 등 )"
      ],
      "metadata": {
        "id": "yrjdAtb2bKy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델별 정확도 시각화\n",
        "plt.figure(figsize = (15,5))\n",
        "sns.barplot(x = 'model', y = 'accuracy', data = df_results)\n",
        "plt.title('Accuracy on the test set (after 1 epoch))', fontsize = 15)\n",
        "plt.ylim(0,1)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JMdcDVJeQxxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델별 Training time 시각화\n",
        "\n",
        "plt.figure(figsize = (15,5))\n",
        "sns.barplot(x = 'model', y = 'Training time (sec)', data = df_results)\n",
        "plt.title('Training time for each model in sec', fontsize = 15)\n",
        "# plt.ylim(0,20)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3be1hWZdRPrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 가장 좋은 성능 & 시간이 적게 드는 모델 선정하여 성능 재확인"
      ],
      "metadata": {
        "id": "SP1WwZOjRgqT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 성능 확인 ______Ex) DenseNet201, ResNet152v2"
      ],
      "metadata": {
        "id": "4VEP8BmhR0Vr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. DenseNet201"
      ],
      "metadata": {
        "id": "x7NWa4cSSAMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df,test_df = train_test_split(df, test_size=0.1, random_state=0)\n",
        "train_generator,test_generator,train_images,val_images,test_images=create_gen()\n",
        "\n",
        "model = get_model(tf.keras.applications.DenseNet201)\n",
        "history = model.fit(train_images,validation_data=val_images,epochs=7)"
      ],
      "metadata": {
        "id": "EZXxlKWoSEeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(history.history)[['accuracy','val_accuracy']].plot()\n",
        "plt.title(\"Accuracy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cGPA9reXSIjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(history.history)[['loss','val_loss']].plot()\n",
        "plt.title(\"Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MELMrOSJSLAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the label of the test_images\n",
        "pred = model.predict(test_images)\n",
        "pred = np.argmax(pred,axis=1)\n",
        "\n",
        "# Map the label\n",
        "labels = (train_images.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "pred = [labels[k] for k in pred]\n",
        "    \n",
        "y_test = list(test_df.Label)\n",
        "acc = accuracy_score(y_test,pred)\n",
        "print(f'Accuracy on the test set: {acc * 100:.2f}%')"
      ],
      "metadata": {
        "id": "Vbk4_fPnSQHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "test데이터를 통해서 성능을 확인\n",
        "\n",
        "Accuracy on the test set: __.__%"
      ],
      "metadata": {
        "id": "SONhpxIvSSEJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. ResNet152v2"
      ],
      "metadata": {
        "id": "ZcVlbofpSis8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df,test_df = train_test_split(df, test_size=0.1, random_state=0)\n",
        "train_generator,test_generator,train_images,val_images,test_images=create_gen()\n",
        "\n",
        "model = get_model(tf.keras.applications.ResNet152V2)\n",
        "history = model.fit(train_images,validation_data=val_images,epochs=5)"
      ],
      "metadata": {
        "id": "_DrN1j2qSpST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(history.history)[['accuracy','val_accuracy']].plot()\n",
        "plt.title(\"Accuracy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pGtIWNAsSriu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(history.history)[['loss','val_loss']].plot()\n",
        "plt.title(\"Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4pmwUEFoSviO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the label of the test_images\n",
        "pred = model.predict(test_images)\n",
        "pred = np.argmax(pred,axis=1)\n",
        "\n",
        "# Map the label\n",
        "labels = (train_images.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "pred = [labels[k] for k in pred]\n",
        "\n",
        "def printmd(string):\n",
        "    # Print with Markdowns    \n",
        "    display(Markdown(string))\n",
        "    \n",
        "y_test = list(test_df.Label)\n",
        "acc = accuracy_score(y_test,pred)\n",
        "printmd(f'# Accuracy on the test set: {acc * 100:.2f}%')"
      ],
      "metadata": {
        "id": "bWaDq5OISx2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy on the test set:"
      ],
      "metadata": {
        "id": "J_O7G3l4S4-A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델의 정밀도와 재현율 확인"
      ],
      "metadata": {
        "id": "p8cO2CuxS8ze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_report = classification_report(y_test, pred, zero_division=1)\n",
        "print(class_report)"
      ],
      "metadata": {
        "id": "pWG10PxgTGq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix 시각화\n",
        "### 히트맵을 통해 시각화 ( 본인외에 전부 어두운색으로 나타나야 Good )"
      ],
      "metadata": {
        "id": "jfqARaYaTNlk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 실전 TEST\n",
        "\n",
        "### 모델을 실제로 확인, 새로운 사진 준비 후 이 사진에 대한 예측률 확인해보기"
      ],
      "metadata": {
        "id": "boO-XegSTgqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from PIL import Image\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
        "def printmd(string):\n",
        "    # Print with Markdowns    \n",
        "    display(Markdown(string))\n",
        "class_dictionary = {'airplane': 0,\n",
        "                    'car': 1,\n",
        "                    'cat': 2,\n",
        "                    'dog': 3,\n",
        "                    'flower': 4,\n",
        "                    'fruit': 5,\n",
        "                    'motorbike': 6,\n",
        "                    'person': 7}\n",
        "IMAGE_SIZE    = (224, 224)\n",
        "number_1 = int(input(\"번호를 입력하세요 : \")) # 10, 50, 100\n",
        "test_image = image.load_img(test_df.iloc[number_1, 0]\n",
        "                            ,target_size =IMAGE_SIZE )\n",
        "test_image = image.img_to_array(test_image)\n",
        "plt.imshow(test_image/255.);\n",
        "\n",
        "test_image = test_image.reshape((1, test_image.shape[0], test_image.shape[1], test_image.shape[2]))\n",
        "test_image = preprocess_input(test_image)\n",
        "prediction = model.predict(test_image)\n",
        "\n",
        "df = pd.DataFrame({'pred':prediction[0]})\n",
        "df = df.sort_values(by='pred', ascending=False, na_position='first')\n",
        "printmd(f\"## 예측률 : {(df.iloc[0]['pred'])* 100:.2f}%\")\n",
        "\n",
        "for x in class_dictionary:\n",
        "  if class_dictionary[x] == (df[df == df.iloc[0]].index[0]):\n",
        "    printmd(f\"### Class prediction = {x}\")\n",
        "    break"
      ],
      "metadata": {
        "id": "bzJ4pRBwT-Dp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 번호 입력시, 그 번호에 대한 이미지 출력\n",
        "### 그 이미지에 대해 예측 라벨, 예측률 출력"
      ],
      "metadata": {
        "id": "PXx40jhRUADN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 여러 이미지 예측\n",
        "# Display picture of the dataset with their labels\n",
        "\n",
        "fig, axes = plt.subplots(nrows=4, ncols=6, figsize=(20, 12),\n",
        "                        subplot_kw={'xticks': [], 'yticks': []})\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(plt.imread(test_df.Filepath.iloc[i]))\n",
        "    ax.set_title(f\"True: {test_df.Label.iloc[i].split('_')[0]}\\nPredicted: {pred[i].split('_')[0]}\", fontsize = 15)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h0JZce3lUTpM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}